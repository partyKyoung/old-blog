{"componentChunkName":"component---src-templates-blog-template-tsx","path":"/2019-10-05-bigdata-hadoop/","webpackCompilationHash":"0b19d7a726d158ee4bf0","result":{"data":{"site":{"siteMetadata":{"title":"Kyoungah's dev blog.","author":"Kyoungah"}},"markdownRemark":{"id":"3c33ca29-febb-53c3-9e15-06dbedf50013","excerpt":"…","html":"<h2>하둡</h2>\n<p>대량의 자료를 처리할 수 있는 큰 컴퓨터 클러스터에서 동작하는 분산 응용 프로그램을 지원하는 프리웨어 자바 소프트웨어 프레임워크 (출처: <a href=\"https://ko.wikipedia.org/wiki/%EC%95%84%ED%8C%8C%EC%B9%98_%ED%95%98%EB%91%A1\">위키백과</a>).</p>\n<p>하둡은 자바로 작성되어 있으며 하둡 공통, 하둡 분산 파일 시스템, 하둡 맵리듀스 세가지 모듈로 구성되어 있다.</p>\n<ul>\n<li>하둡 공통: 다른 모듈들을 지원하는 공통 유틸리티 모음.</li>\n<li>하둡 분산 파일 시스템: 하둡 공통을 이용하여 대용량 데이터를 다수의 컴퓨터에 분산시켜 빠르게 처리할 수 있는 분산 파일 시스템.</li>\n<li>하둡 맵리듀스: 분산 파일 시스템에 저장된 대용량 데이터를 병령 처리하기 위한 소프트웨어 프레임워크. </li>\n</ul>\n<h2>하둡 분산 파일 시스템 (HDFS)</h2>\n<p>하둡 공통을 이용하여 대용량 데이터를 다수의 컴퓨터에 분산시켜 빠르게 처리할 수 있는 분산 파일 시스템. 마스터노드와 슬레이브 노드로 구성되어 있다.</p>\n<p>HDFS는 메타데이터에 접근하거나 데이터를 변경하는 작업의 대기시간을 희생하는 대신 데이터를 읽어 오는 작업의 처리량을 높여 큰 데이터를 한번에 빠르게 가져올 수 있도록 설계되었다. 이러한 설계는 하둡이 데이터의 실시간 처리가 아닌 데이터의 일괄 처리에 최적화된 플랫폼이라는 데에 기인한다.</p>\n<p>데이터의 일괄 처리를 위해서는 기존에 수집된 데이터를 수정할 필요가 없으므로 HDFS에서는 한번 쓰기 완료된 데이터의 수정이 불가능하고 오직 덮어쓰기만 가능하도록 되어 있다.  </p>\n<ul>\n<li>마스터 노드(네임노드): 슬레이브 노드의 동작 상태를 실시간으로 관리하고 최대 수천 대의 데이터노드에 분산 저장되어 있는 메타데이터를 관리한다. 1대로 구성되어 있다.</li>\n<li>슬레이브 노드(데이터노드): 실체 데이터를 여러 개의 블록으로 쪼개서 몇 대의 데이터 노드에 복제해서 보관하는 방식으로 데이터들을 분산 저장 한다. 수십 ~ 수천대로 이루어져있다.</li>\n</ul>\n<blockquote>\n<p>메타데이터: '데이터에 대한 데이터'로 데이터의 생성 수단, 목적, 생성 날짜 및 시각, 만든 사람 등 데이터 파일의 내용과 맥락을 알려주는 데이터.</p>\n</blockquote>\n<p>이와 같은 방식을 사용하면 데이터노드 한두대가 고장 나더라도 데이터를 잃지 않기 떄문에 '신뢰성'이 확보된다. 또한 저장용량이 부족해지면 저가의 데이터노드를 추가하여 네임노드에 등록하는 것으로 시스템의 중단 없이 용량을 확장시킬 수 있기 떄문에 '확장성'이 구현된다. 그러나 비용문제로 저가의 서버를 이용하는 것을 전제로 하고 있기 때문에 디스크나 서버의 고장이 자주 발생할 수 있으므로 '고장감내성'이 중요하게 고려된다.</p>\n<h2>맵리듀스</h2>\n<p>HDFS상에서 동작하는 데이터 분석 프레임워크. 일반 프로그래밍 방법과는 다른 데이터 중심 프로그래밍 모형을 제공한다. </p>\n<p>분산된 환경에서의 프로그래밍은 분산된 작업의 스케줄링이나 일부 서버의 고장, 서버 간 네트워크 구성 등 많은 문제를 고려해야 하는데 맵리듀스에서는 이런 복잡한 문제들이 플랫폼 차원에서 단순화되어 프로그래머는 데이터의 배치처리를 위한 맵과 리듀스 함수만 작성하면 되도록 구현되어 있다. 이 함수는 데이터노드에서 실행된다.</p>\n<p>맵리듀스에서 사용하는 프로그래밍 모형은 함수들로 구성되어 있고 각 함수의 입력은 모두 키와 값이 쌍으로 구성되어 있다. </p>\n<ul>\n<li>Map: HDFS에서 불러온 데이터를 가공하여 새로운 &#x3C;키, 값> 집합을 출력한다.</li>\n<li>Reduce: 같은 키를 갖는 값들을 묶어 &#x3C;키, (값1, 값2, 값3, ...)> 형식으로 새로운 &#x3C;키, 값> 쌍의 집합을 만든다.</li>\n</ul>\n<p>멥 작업에서 생성된 결과물이 리듀스 작업의 입력으로 들어가기 때문에 많은 &#x3C;키, 값> 쌍이 한 노드로 전달된다면 데이터 전송 오버헤드가 커진다. 이를 감소시키기 위해 맵 함수가 특정한 컴바인 함수를 갖도록 프로그래머가 정해줄 수 있다.</p>\n<blockquote>\n<p>컴바인 함수: 노드 간 데이터 전송을 최소하 하기 위해 사용하는 함수.</p>\n</blockquote>","frontmatter":{"title":"하둡","date":"October 03, 2019"}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/2019-10-05-bigdata-hadoop/"}}}